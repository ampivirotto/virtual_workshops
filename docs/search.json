[
  {
    "objectID": "austen/austen.html",
    "href": "austen/austen.html",
    "title": "Data Tutorials",
    "section": "",
    "text": "Data Tutorials\n\n\nInteractive Python Tutorial: Jane Austen Text Analysis\n\nüè† Back to Tutorials Home"
  },
  {
    "objectID": "austen/austen.html#analyzing-jane-austens-novels",
    "href": "austen/austen.html#analyzing-jane-austens-novels",
    "title": "Data Tutorials",
    "section": "Analyzing Jane Austen‚Äôs Novels",
    "text": "Analyzing Jane Austen‚Äôs Novels\nIn honor of Jane Austen‚Äôs 250th birthday we will be using her novels to begin to explore text analysis. You‚Äôll learn how to analyze the text of Jane Austen‚Äôs novels using Python. We‚Äôll cover text collection, sentiment analysis, and some basic visualization techniques.\n\n\n\nJane Austen birthday image"
  },
  {
    "objectID": "austen/austen.html#step-1-collecting-texts-from-project-gutenberg",
    "href": "austen/austen.html#step-1-collecting-texts-from-project-gutenberg",
    "title": "Data Tutorials",
    "section": "Step 1: Collecting Texts from Project Gutenberg",
    "text": "Step 1: Collecting Texts from Project Gutenberg\nIn this section, you will learn how to pull Jane Austen novels from Project Gutenberg for analysis. The full version (available in Colab) includes all necessary code and explanations to download the text directly from Project Gutenberg.\n Launch Full Notebook in Colab \nIn the cell below, we give an example of how you might define the list of Jane Austen‚Äôs novels by title or ID number. This can then be used to download several different texts from Project Gutenberg at once. However, for this example we start with a single book ‚ÄúPride and Prejudice‚Äù and we show how you can use the requests package to download the text.\n\nNote: The example below shows how you‚Äôd do this with requests in a full Python environment (Colab or Binder). Browser Pyodide sessions cannot use the requests library to make arbitrary network calls so this can only be completed in a full python environment.\n\njane_austen_book_titles = [\"Pride and Prejudice\", \"Sense and Sensibility\", \"Emma\"] ## Option 1: by title\njane_austen_book_ids = [1342, 161, 158]  ## Option 2: by Gutenberg ID number\n\n## let's start with downloading one book as an example\nbook_id = jane_austen_book_ids[0]  # Pride and Prejudice\n\nimport requests ## to make HTTP requests\nbook_url = f\"https://www.gutenberg.org/cache/epub/{book_id}/pg{book_id}.txt\"\n\nresponse = requests.get(book_url) ## this makes the call to the website to download the text\nif response.status_code == 200: # check if the request was successful\n    book_text = response.text\n    print(f\"Successfully downloaded book ID {book_id}\")\nelse:\n    print(f\"Failed to download book ID {book_id}\")\nNotice how we downloaded the text file by making an HTTP GET request to the Gutenberg website. The text is then stored in the book_text variable for further analysis. We can do a quick sanity check to make sure we‚Äôre downloading the correct file by following the link we created: Notice how we downloaded the text file by making an HTTP GET request to the Gutenberg website. The text is then stored in the book_text variable for further analysis. We can do a quick sanity check to make sure we‚Äôre downloading the correct file by following the link we created: https://www.gutenberg.org/cache/epub/1342/pg1342.txt."
  },
  {
    "objectID": "austen/austen.html#step-2-sentiment-analysis",
    "href": "austen/austen.html#step-2-sentiment-analysis",
    "title": "Data Tutorials",
    "section": "Step 2: Sentiment Analysis",
    "text": "Step 2: Sentiment Analysis\nNow that we have the text of a single book ‚ÄúPride and Prejudice‚Äù grabbed, we can perform some basic sentiment analysis. What is sentiment analysis? Using natural language processing (NLP) we can analyze the emotions expressed in a text. Here are three different approaches we can take to better understand the text. Each exercise is fully developed in the Colab notebook linked above, but these code snippets give you a starting point.\n\nExercise: Count Words in a Sample Text\nOne thing you might want to understand about your text is how often each word appears. We can do this by counting the occurrences of each word. Try changing the sample_text variable to see how that changes the result from the cell.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nExercise: Filter Stop Words\nYou might notice that in the sentence above ‚Äúis‚Äù occurs twice, but doesn‚Äôt affect the overall meaning. Can you imagine other words that appear often but don‚Äôt have significant affect on the meaning of the text? Stopwords are common words that may not carry significant meaning in text analysis. We can filter these out to focus on more meaningful words.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nExercise: Compute Average Sentiment\nIn the actual Colab notebook, we would calculate the sentiment scores using a library like NLTK. For this sample code though, we will use dummy data sentiment scores.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "austen/austen.html#step-3-visualizing-sentiment-trajectories",
    "href": "austen/austen.html#step-3-visualizing-sentiment-trajectories",
    "title": "Data Tutorials",
    "section": "Step 3: Visualizing Sentiment Trajectories",
    "text": "Step 3: Visualizing Sentiment Trajectories\nHere is a small interactive demo of sentiment trajectories using preloaded data. This demo visualizes sample data, but in the full notebook, we would use real sentiment analysis results.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "austen/austen_exercise.html",
    "href": "austen/austen_exercise.html",
    "title": "Analzying Jane Austen‚Äôs Novels",
    "section": "",
    "text": "In honor of Jane Austen‚Äôs 250th birthday we will be using her novels to begin to explore text analysis. You‚Äôll learn how to analyze the text of Jane Austen‚Äôs novels using Python. We‚Äôll cover text collection, sentiment analysis, and some basic visualization techniques.\n\n## Import necessary libraries\n## data table manipulation and analysis\nimport pandas as pd\n\n## regular expressions, csv handling, counting elements\nimport re\nimport csv\nfrom collections import Counter\n\n## handling byte streams and https requests\nfrom io import BytesIO\nimport requests\n\n## sentiment analysis and natural language processing\nimport nltk\nfrom nltk.sentiment import SentimentIntensityAnalyzer  ## library for sentiment analysis\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\n\n## plotting and visualization\nimport matplotlib.pyplot as plt\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[4], line 3\n      1 ## Import necessary libraries\n      2 ## data table manipulation and analysis\n----&gt; 3 import pandas as pd\n      5 ## regular expressions, csv handling, counting elements\n      6 import re\n\nFile c:\\Users\\apivirotto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py:26\n     22 del _hard_dependencies, _dependency, _missing_dependencies\n     24 try:\n     25     # numpy compat\n---&gt; 26     from pandas.compat import (\n     27         is_numpy_dev as _is_numpy_dev,  # pyright: ignore[reportUnusedImport] # noqa: F401\n     28     )\n     29 except ImportError as _err:  # pragma: no cover\n     30     _module = _err.name\n\nFile c:\\Users\\apivirotto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py:28\n     17 from pandas.compat._constants import (\n     18     IS64,\n     19     ISMUSL,\n   (...)\n     25     WARNING_CHECK_DISABLED,\n     26 )\n     27 import pandas.compat.compressors\n---&gt; 28 from pandas.compat.numpy import is_numpy_dev\n     29 from pandas.compat.pyarrow import (\n     30     HAS_PYARROW,\n     31     pa_version_under10p1,\n   (...)\n     41     pa_version_under21p0,\n     42 )\n     44 if TYPE_CHECKING:\n\nFile c:\\Users\\apivirotto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\compat\\numpy\\__init__.py:9\n      6 from pandas.util.version import Version\n      8 # numpy versioning\n----&gt; 9 _np_version = np.__version__\n     10 _nlv = Version(_np_version)\n     11 np_version_lt1p23 = _nlv &lt; Version(\"1.23\")\n\nAttributeError: module 'numpy' has no attribute '__version__'\n\n\n\n\nGUTENBERG_CSV_URL = \"https://www.gutenberg.org/cache/epub/feeds/pg_catalog.csv.gz\"\n\nr = requests.get(GUTENBERG_CSV_URL)\nwith BytesIO(r.content) as f:\n    df = pd.read_csv(f, compression='gzip', quoting=csv.QUOTE_ALL)\ndf.head()\n\n\n\n\n\n\n\n\nText#\nType\nIssued\nTitle\nLanguage\nAuthors\nSubjects\nLoCC\nBookshelves\n\n\n\n\n0\n1\nText\n1971-12-01\nThe Declaration of Independence of the United ...\nen\nJefferson, Thomas, 1743-1826\nUnited States -- History -- Revolution, 1775-1...\nE201; JK\nPolitics; American Revolutionary War; United S...\n\n\n1\n2\nText\n1972-12-01\nThe United States Bill of Rights\\r\\nThe Ten Or...\nen\nUnited States\nCivil rights -- United States -- Sources; Unit...\nJK; KF\nPolitics; American Revolutionary War; United S...\n\n\n2\n3\nText\n1973-11-01\nJohn F. Kennedy's Inaugural Address\nen\nKennedy, John F. (John Fitzgerald), 1917-1963\nUnited States -- Foreign relations -- 1961-196...\nE838\nCategory: Essays, Letters & Speeches; Category...\n\n\n3\n4\nText\n1973-11-01\nLincoln's Gettysburg Address\\r\\nGiven November...\nen\nLincoln, Abraham, 1809-1865\nConsecration of cemeteries -- Pennsylvania -- ...\nE456\nUS Civil War; Category: Essays, Letters & Spee...\n\n\n4\n5\nText\n1975-12-01\nThe United States Constitution\nen\nUnited States\nUnited States -- Politics and government -- 17...\nJK; KF\nUnited States; Politics; American Revolutionar...\n\n\n\n\n\n\n\n\nausten_rows = df[(df['Authors'].str.contains('Austen, Jane', na=False)) & (df['Type'] == 'Text') & (df['Language'] == 'en')][:8]\n\nausten_rows\n\n\n\n\n\n\n\n\nText#\nType\nIssued\nTitle\nLanguage\nAuthors\nSubjects\nLoCC\nBookshelves\n\n\n\n\n104\n105\nText\n1994-02-01\nPersuasion\nen\nAusten, Jane, 1775-1817\nEngland -- Social life and customs -- 19th cen...\nPR\nCategory: Novels; Category: British Literature\n\n\n120\n121\nText\n1994-04-01\nNorthanger Abbey\nen\nAusten, Jane, 1775-1817\nEngland -- Social life and customs -- 19th cen...\nPR\nGothic Fiction; Category: Novels; Category: Cl...\n\n\n140\n141\nText\n1994-06-01\nMansfield Park\nen\nAusten, Jane, 1775-1817\nEngland -- Fiction; Young women -- Fiction; Lo...\nPR\nCategory: Novels; Category: British Literature\n\n\n157\n158\nText\n1994-08-01\nEmma\nen\nAusten, Jane, 1775-1817\nHumorous stories; England -- Fiction; Young wo...\nPR\nCategory: Novels; Category: British Literature\n\n\n160\n161\nText\n1994-09-01\nSense and Sensibility\nen\nAusten, Jane, 1775-1817\nEngland -- Social life and customs -- 19th cen...\nPR\nCategory: Romance; Category: Novels; Category:...\n\n\n927\n946\nText\n1997-06-01\nLady Susan\nen\nAusten, Jane, 1775-1817\nEngland -- Fiction; Widows -- Fiction; Mate se...\nPR\nCategory: Novels; Category: British Literature\n\n\n1190\n1212\nText\n1998-02-01\nLove and Freindship [sic]\nen\nAusten, Jane, 1775-1817\nEssays; Epistolary fiction; England -- Social ...\nPR\nCategory: Romance; Category: Humour; Category:...\n\n\n1320\n1342\nText\n1998-06-01\nPride and Prejudice\nen\nAusten, Jane, 1775-1817\nEngland -- Fiction; Young women -- Fiction; Lo...\nPR\nBest Books Ever Listings; Harvard Classics; Ca...\n\n\n\n\n\n\n\n\nall_books_text = {}\n\n\ndef clean_sentence(sentence):\n    \"\"\"Clean a sentence by removing punctuation and converting to lowercase.\"\"\"\n    # Remove asterisks, underscores, and other decorative symbols\n    cleaned_sentence = re.sub(r'[_*#&lt;&gt;+=\\\\/\\[\\]{}|]', '', sentence)\n\n\n    # Replace multiple newlines or spaces with single space\n    cleaned_sentence = re.sub(r'\\s+', ' ', cleaned_sentence)\n\n    # Remove weird characters (non-ASCII)\n    cleaned_sentence = cleaned_sentence.encode('ascii', errors='ignore').decode()\n\n    # Strip leading/trailing spaces\n    cleaned_sentence = cleaned_sentence.strip()\n\n    return cleaned_sentence\n\n\nn_books = len(austen_rows)\nn_cols = 2  # Adjust for layout you like\nn_rows = (n_books + n_cols - 1) // n_cols\n\nfig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 12), sharex=True, sharey=True)\naxes = axes.flatten()\n\nsegment = 25\nsia = SentimentIntensityAnalyzer()\n\nfor idx, bookID in enumerate(austen_rows[\"Text#\"]):\n    url = f\"https://www.gutenberg.org/cache/epub/{bookID}/pg{bookID}.txt\"\n    bookname = austen_rows[austen_rows[\"Text#\"] == bookID][\"Title\"].values[0]\n    \n    response = requests.get(url)  ## Make a GET request to the URL\n    if response.status_code == 200:  ## Check if the request was successful\n        print(f\"Successfully retrieved the book {bookname}.\")\n        text = response.text\n    else:\n        print(f\"Failed to retrieve the book page. Status code: {response.status_code}\")\n\n    # Clean the text\n\n    ## remove the header and footer from the response text \n    start = response.text.find(\"*** START OF THE PROJECT GUTENBERG EBOOK\")  ## Find the start of the book text\n    end = response.text.find(\"*** END OF THE PROJECT GUTENBERG EBOOK\")  ## Find the end of the book text\n    cleaned_text = response.text[start:end]  ## Extract the book text between the start and end markers\n\n    all_books_text[bookID] = [bookname, cleaned_text] ## store the book name and cleaned text in a dictionary\n\n    words = re.findall(r'\\b[a-z]+\\b', cleaned_text.lower()) ## find all words in the cleaned text\n    words = [word for word in words if word not in stop_words] ## remove stop words from the list of words\n    word_counts = Counter(words) ## count the frequency of each word in the list of words\n\n\n    \"\"\"\n    print(f\"Most common words in {bookname}:\")\n    for word, count in word_counts.most_common(10): ## Print the 10 most common words\n        print(f\"{word}: {count}\")\n    \"\"\"\n\n    sentences = nltk.sent_tokenize(cleaned_text)  ## split the cleaned text into sentences using NLTK's sentence tokenizer\n\n    results = []\n\n    for sentence in sentences:\n        cleaned_sentence = clean_sentence(sentence)\n        sentiment_scores = sia.polarity_scores(cleaned_sentence)  ## Get the sentiment scores for the sentence\n        results.append((cleaned_sentence, sentiment_scores['compound']))  ## Append the sentiment scores to the results list\n\n    sentiment_df = pd.DataFrame(results, columns=['Sentence', 'Sentiment']) ## Convert the results list to a DataFrame\n\n    # Extract sentiment scores only\n    sentiment_scores = [s for (_, s) in results]\n    \n    # Compute average sentiment per segment\n    avgScores = {\n        i: sum(sentiment_scores[i*segment:(i+1)*segment]) / segment\n        for i in range(len(sentiment_scores)//segment)\n    }\n\n    # Plot each book in its own panel\n    ax = axes[idx]\n    ax.plot(list(avgScores.keys()), list(avgScores.values()), \n            marker='o', linestyle='-', alpha=0.7)\n    ax.axhline(0, color='black', linestyle='--', linewidth=0.8)\n    ax.set_title(bookname, fontsize=10)\n    ax.set_ylim(-1, 1)\n\n\n# Clean up any unused subplots\nfor ax in axes[len(austen_rows):]:\n    ax.axis('off')\n\nfig.suptitle(\"Sentiment Trajectories Across Jane Austen‚Äôs Novels\", fontsize=14)\nfig.supxlabel(f\"Segment (each = {segment} sentences)\")\nfig.supylabel(\"Average Sentiment Score\")\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()\n\n\nSuccessfully retrieved the book Persuasion.\nSuccessfully retrieved the book Northanger Abbey.\nSuccessfully retrieved the book Mansfield Park.\nSuccessfully retrieved the book Emma.\nSuccessfully retrieved the book Sense and Sensibility.\nSuccessfully retrieved the book Lady Susan.\nSuccessfully retrieved the book Love and Freindship [sic].\nSuccessfully retrieved the book Pride and Prejudice."
  }
]